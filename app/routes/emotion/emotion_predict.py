from fastapi import APIRouter
from fastapi import FastAPI, Request
from pydantic import BaseModel
import numpy as np
import tensorflow as tf
from transformers import TFBertForSequenceClassification, BertTokenizer
from sklearn.preprocessing import LabelEncoder
from fastapi.responses import JSONResponse
import os
import json

#db
from database import get_connection
from datetime import datetime

router = APIRouter()

# ìš”ì²­ ë°ì´í„° í˜•ì‹ ì •ì˜
class TextInput(BaseModel):
    text: str


# í´ë˜ìŠ¤ ë””ì½”ë”©

label_encoder = LabelEncoder()
label_encoder.classes_ = np.array(['ê¸°ì¨','ë‹¹í™©','ë¶„ë…¸','ë¶ˆì•ˆ','ìŠ¬í””'])  # ì‹¤ì œ í•™ìŠµì— ì‚¬ìš©í•œ ìˆœì„œëŒ€ë¡œ


# ì˜ˆì¸¡ í•¨ìˆ˜
def predict_emotion(text: str):

    # ì„œë¹„ìŠ¤ì— ì‚¬ìš©ì¤‘ì¸ jsoníŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    METRICS_FILE = os.path.join(os.path.dirname(__file__), '..','..','models','emotion','emotion_model_run.json')
    # ëª¨ë¸ ê²½ë¡œ
    model_dir = os.path.join(os.path.dirname(__file__), '..', '..','..', 'models', 'emotion')

    with open(METRICS_FILE, "r") as f:
        metrics = json.load(f)

    latest_model_name = metrics[0]["model_name"]
    model_path = os.path.join(model_dir, latest_model_name)

    model = TFBertForSequenceClassification.from_pretrained(model_path)
    tokenizer = BertTokenizer.from_pretrained(model_path)
    
    inputs = tokenizer([text], padding=True, truncation=True, return_tensors='tf')
    outputs = model(inputs)
    logits = outputs.logits
    probs = tf.nn.softmax(logits, axis=-1).numpy()
    pred_class = np.argmax(probs, axis=1)[0]
    decoded_label = label_encoder.inverse_transform([pred_class])[0]
    return decoded_label, probs[0].tolist()


@router.post("/predict_emotion")
async def predict(request: Request):
    body_bytes = await request.body()
    print("ğŸ“¦ ìˆ˜ì‹ ëœ ì›ë³¸ ë°”ë””:", body_bytes.decode("utf-8"))
    
    json_data = await request.json()
    text = json_data.get("text")

    emotion, prob = predict_emotion(text)

    # í˜„ì¬ ë‚ ì§œ (ì›” ë‹¨ìœ„)
    date_str = datetime.now().strftime("%Y-%m-%d")

    # DB ì €ì¥
    conn = get_connection()
    try:
        with conn.cursor() as cursor:
            sql = "INSERT INTO emotionData (date, input, output) VALUES (%s, %s, %s)"
            cursor.execute(sql, (date_str, text, emotion))
        conn.commit()
    finally:
        conn.close()

    return JSONResponse(content={"emotion": emotion})
